{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a129e317-2c40-4b14-9e09-e0fd77d882c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Assignment 5.3 – Hyperparameter Tuning (STEDI)\n",
    "\n",
    "This notebook:\n",
    "1. Loads the saved feature pipeline + transformed train/test datasets from the Workspace repo path (NOT DBFS).\n",
    "2. Converts loaded data to numeric float matrices using `to_float_matrix`.\n",
    "3. Runs **reasonable** `GridSearchCV` for:\n",
    "   - Logistic Regression\n",
    "   - Random Forest\n",
    "4. Compares tuned models and selects the best model.\n",
    "5. Saves **ONLY** the final best model back to the Workspace repo path.\n",
    "\n",
    "**Important constraints:**\n",
    "- Do NOT use `/dbfs`, `FileStore`, or `dbutils.fs`.\n",
    "- Always verify files with `os.listdir`.\n",
    "- Always print shapes after loading.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b72129c8-f78a-4a97-8caf-a9e1c03d823b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "from scipy import sparse\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# --- Determine current repo directory ---\n",
    "BASE_PATH = os.getcwd()\n",
    "\n",
    "print(\"Current working directory:\")\n",
    "print(BASE_PATH)\n",
    "\n",
    "print(\"\\nFiles in BASE_PATH:\")\n",
    "print(os.listdir(BASE_PATH))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7077f377-5c2b-46a2-8c8e-570db0a1910a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "base_path = (Path.cwd() / \"..\" / \"etl_pipeline\").resolve()\n",
    "\n",
    "pipeline_path = base_path / \"stedi_feature_pipeline.pkl\"\n",
    "X_train_path = base_path / \"X_train_transformed.pkl\"\n",
    "X_test_path = base_path / \"X_test_transformed.pkl\"\n",
    "y_train_path = base_path / \"y_train.pkl\"\n",
    "y_test_path = base_path / \"y_test.pkl\"\n",
    "\n",
    "print(\"BASE_PATH:\", base_path)\n",
    "print(\"Files:\", [p.name for p in base_path.iterdir()])\n",
    "\n",
    "print(\"\\nChecking if files exist...\")\n",
    "print(\"Pipeline:\", pipeline_path.exists())\n",
    "print(\"X_train:\", X_train_path.exists())\n",
    "print(\"X_test:\", X_test_path.exists())\n",
    "print(\"y_train:\", y_train_path.exists())\n",
    "print(\"y_test:\", y_test_path.exists())\n",
    "\n",
    "print(\"\\nLoading saved pipeline and datasets...\")\n",
    "try:\n",
    "    feature_pipeline = joblib.load(pipeline_path)\n",
    "    X_train_transformed = joblib.load(X_train_path)\n",
    "    X_test_transformed = joblib.load(X_test_path)\n",
    "    y_train = joblib.load(y_train_path)\n",
    "    y_test = joblib.load(y_test_path)\n",
    "    print(\"✓ Loading complete!\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error loading files: {type(e).__name__}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "93bbf904-d239-4a80-90a5-c769473b69c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import joblib\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "# FIX: ensure BASE_PATH exists in this cell\n",
    "BASE_PATH = os.path.abspath(os.path.join(os.getcwd(), \"..\", \"etl_pipeline\"))\n",
    "print(\"BASE_PATH:\", BASE_PATH)\n",
    "print(\"Files:\", os.listdir(BASE_PATH))\n",
    "\n",
    "def load_pkl(path):\n",
    "    \"\"\"\n",
    "    Robust loader: tries joblib first, falls back to pickle.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return joblib.load(path)\n",
    "    except Exception as e:\n",
    "        print(f\"joblib failed on {path}: {e}\")\n",
    "        with open(path, \"rb\") as f:\n",
    "            return pickle.load(f)\n",
    "\n",
    "pipeline_path = os.path.join(BASE_PATH, \"stedi_feature_pipeline.pkl\")\n",
    "xtr_path = os.path.join(BASE_PATH, \"X_train_transformed.pkl\")\n",
    "xte_path = os.path.join(BASE_PATH, \"X_test_transformed.pkl\")\n",
    "ytr_path = os.path.join(BASE_PATH, \"y_train.pkl\")\n",
    "yte_path = os.path.join(BASE_PATH, \"y_test.pkl\")\n",
    "\n",
    "# Validate files exist BEFORE loading\n",
    "required = [pipeline_path, xtr_path, xte_path, ytr_path, yte_path]\n",
    "missing = [p for p in required if not os.path.exists(p)]\n",
    "print(\"Missing files:\", missing)\n",
    "\n",
    "assert len(missing) == 0, \"One or more required .pkl files are missing.\"\n",
    "\n",
    "# Load\n",
    "feature_pipeline = load_pkl(pipeline_path)\n",
    "X_train_transformed = load_pkl(xtr_path)\n",
    "X_test_transformed  = load_pkl(xte_path)\n",
    "y_train = load_pkl(ytr_path)\n",
    "y_test  = load_pkl(yte_path)\n",
    "\n",
    "# Print types\n",
    "print(\"\\nType checks:\")\n",
    "print(type(feature_pipeline))\n",
    "print(type(X_train_transformed))\n",
    "print(type(X_test_transformed))\n",
    "print(type(y_train))\n",
    "print(type(y_test))\n",
    "\n",
    "# Shape checks\n",
    "def get_shape(x):\n",
    "    if sparse.issparse(x):\n",
    "        return x.shape\n",
    "    return np.array(x).shape\n",
    "\n",
    "print(\"\\nShape checks:\")\n",
    "print(\"X_train_transformed:\", get_shape(X_train_transformed))\n",
    "print(\"X_test_transformed:\", get_shape(X_test_transformed))\n",
    "print(\"y_train:\", np.array(y_train).shape)\n",
    "print(\"y_test:\", np.array(y_test).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "93a5a3c5-c7a5-4d8e-befa-03e3996bc768",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "print(\"Current working directory:\")\n",
    "print(os.getcwd())\n",
    "\n",
    "print(\"\\nFiles in current directory:\")\n",
    "print(os.listdir())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02b22e7c-5a48-488d-b101-d9b408706385",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "print(\"Current directory:\")\n",
    "print(os.getcwd())\n",
    "\n",
    "print(\"\\nListing parent directories:\")\n",
    "print(os.listdir(\"/Workspace/Users/dec816@ensign.edu\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b2aa0ec-455f-49c1-9214-7cc960d47eec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 2 — Convert to Numeric Matrices (`to_float_matrix`)\n",
    "\n",
    "Some ML models require numeric float matrices.\n",
    "We convert:\n",
    "- `X_train_transformed` → `X_train_float`\n",
    "- `X_test_transformed` → `X_test_float`\n",
    "\n",
    "We also ensure `y_train` and `y_test` are 1D arrays.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "33ba36c9-1128-44e4-92c4-68f2a21996f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Notebook is running from .../notebooks\n",
    "# PKL files are in sibling folder .../etl_pipeline\n",
    "BASE_PATH = os.path.abspath(os.path.join(os.getcwd(), \"..\", \"etl_pipeline\"))\n",
    "\n",
    "print(\"CWD:\", os.getcwd())\n",
    "print(\"BASE_PATH:\", BASE_PATH)\n",
    "print(\"BASE_PATH exists:\", os.path.exists(BASE_PATH))\n",
    "print(\"Files in BASE_PATH:\")\n",
    "print(os.listdir(BASE_PATH))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ab87309-d897-486b-886b-0d9c7740f36e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def to_float_matrix(X):\n",
    "    \"\"\"\n",
    "    Converts X into a numeric float matrix.\n",
    "    Handles:\n",
    "    - scipy sparse matrices\n",
    "    - numpy arrays\n",
    "    - lists\n",
    "    \"\"\"\n",
    "    if sparse.issparse(X):\n",
    "        return X.astype(np.float64)\n",
    "    X = np.array(X)\n",
    "    return X.astype(np.float64)\n",
    "\n",
    "X_train_float = to_float_matrix(X_train_transformed)\n",
    "X_test_float  = to_float_matrix(X_test_transformed)\n",
    "\n",
    "y_train_arr = np.array(y_train).ravel()\n",
    "y_test_arr  = np.array(y_test).ravel()\n",
    "\n",
    "print(\"After conversion:\")\n",
    "print(\"X_train_float type:\", type(X_train_float), \"shape:\", get_shape(X_train_float))\n",
    "print(\"X_test_float type:\", type(X_test_float), \"shape:\", get_shape(X_test_float))\n",
    "print(\"y_train_arr shape:\", y_train_arr.shape, \"dtype:\", y_train_arr.dtype)\n",
    "print(\"y_test_arr shape:\", y_test_arr.shape, \"dtype:\", y_test_arr.dtype)\n",
    "\n",
    "# Optional: check sparsity\n",
    "if sparse.issparse(X_train_float):\n",
    "    nnz = X_train_float.nnz\n",
    "    total = X_train_float.shape[0] * X_train_float.shape[1]\n",
    "    print(f\"Sparse matrix nnz={nnz:,} out of {total:,} ({nnz/total:.6f} density)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f1a4fa40-c314-4497-8ced-c49eb43a8c53",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 3 — Hyperparameter Tuning: Logistic Regression (GridSearchCV)\n",
    "\n",
    "We run a **small, reasonable** grid to avoid long runtimes.\n",
    "We use 3-fold CV and accuracy scoring.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2b0c9a6-6571-4bc9-99e7-ed6093a5e65a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression()\n",
    "\n",
    "# Reasonable grid (fast but still meaningful)\n",
    "log_reg_param_grid = {\n",
    "    \"C\": [0.1, 1.0, 10.0],\n",
    "    \"solver\": [\"liblinear\", \"saga\"],\n",
    "    \"penalty\": [\"l2\"],\n",
    "    \"max_iter\": [200, 500]\n",
    "}\n",
    "\n",
    "log_reg_grid = GridSearchCV(\n",
    "    estimator=log_reg,\n",
    "    param_grid=log_reg_param_grid,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "log_reg_grid.fit(X_train_float, y_train_arr)\n",
    "\n",
    "print(\"Best Logistic Regression Params:\", log_reg_grid.best_params_)\n",
    "print(\"Best CV Accuracy (LogReg):\", log_reg_grid.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "47c48d7e-2663-4e88-8b53-ee37b5834a39",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler(with_mean=False)),\n",
    "    (\"clf\", LogisticRegression())\n",
    "])\n",
    "\n",
    "# MUCH smaller grid (only liblinear, one max_iter)\n",
    "param_grid = {\n",
    "    \"clf__C\": [0.1, 1.0, 10.0],\n",
    "    \"clf__solver\": [\"liblinear\"],\n",
    "    \"clf__penalty\": [\"l2\"],\n",
    "    \"clf__max_iter\": [2000]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    pipe,\n",
    "    param_grid,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid.fit(X_train_float, y_train_arr)\n",
    "\n",
    "print(\"Best Params:\", grid.best_params_)\n",
    "print(\"Best CV Accuracy:\", grid.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59f8f831-34a3-4ee4-ab5e-2ffd76ccf456",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 3b — Evaluate Tuned Logistic Regression on Test Set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3396f43-cc8d-4211-96fc-74e41eda189c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Step 3b — Evaluate Tuned Logistic Regression on Test Set"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "best_lr = grid_lr.best_estimator_\n",
    "\n",
    "y_pred_lr = best_lr.predict(X_test_float)\n",
    "lr_test_acc = accuracy_score(y_test_arr, y_pred_lr)\n",
    "\n",
    "print(\"Tuned Logistic Regression Test Accuracy:\", lr_test_acc)\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test_arr, y_pred_lr))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test_arr, y_pred_lr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18cfad63-a38d-4596-a4a9-542614fbfc74",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 4 — Hyperparameter Tuning: Random Forest (GridSearchCV)\n",
    "\n",
    "Random Forest can get slow if the grid is too large.\n",
    "This is a **small grid** designed to stay within a reasonable runtime.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "11cf10d7-0cea-40cf-b96b-78b64ae91cbd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "param_grid_rf = {\n",
    "    \"n_estimators\": [100, 200],\n",
    "    \"max_depth\": [None, 20],\n",
    "    \"min_samples_split\": [2, 5]\n",
    "}\n",
    "\n",
    "grid_rf = GridSearchCV(\n",
    "    rf,\n",
    "    param_grid_rf,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_rf.fit(X_train_float, y_train_arr)\n",
    "\n",
    "print(\"Best RF Params:\", grid_rf.best_params_)\n",
    "print(\"Best RF CV Accuracy:\", grid_rf.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ff9ec11-da2d-4d33-8825-20263deac798",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 4b — Evaluate Tuned Random Forest on Test Set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff1e55b7-da41-4a4f-b352-b12e9cda5889",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "best_rf = grid_rf.best_estimator_\n",
    "\n",
    "y_pred_rf = best_rf.predict(X_test_float)\n",
    "rf_test_acc = accuracy_score(y_test_arr, y_pred_rf)\n",
    "\n",
    "print(\"Tuned Random Forest Test Accuracy:\", rf_test_acc)\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test_arr, y_pred_rf))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test_arr, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c04dd659-cd85-4941-9bf2-c428476a3157",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 5 — Compare Tuned Models and Select Best\n",
    "\n",
    "We compare **test accuracy** (not just CV accuracy) and select the best model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d97c3665-caab-4700-85b1-a5ba16918728",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"LR Test Accuracy:\", lr_test_acc)\n",
    "print(\"RF Test Accuracy:\", rf_test_acc)\n",
    "\n",
    "if rf_test_acc > lr_test_acc:\n",
    "    best_model_name = \"RandomForestClassifier (Tuned)\"\n",
    "    best_model = best_rf\n",
    "    best_acc = rf_test_acc\n",
    "else:\n",
    "    best_model_name = \"LogisticRegression (Tuned)\"\n",
    "    best_model = best_lr\n",
    "    best_acc = lr_test_acc\n",
    "\n",
    "print(\"\\n✅ Selected Best Model:\", best_model_name)\n",
    "print(\"Best Model Test Accuracy:\", best_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5dd969f-421e-4b71-8f1e-69ac5986bba1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 6 — Save ONLY the Final Best Model (Workspace Repo Path)\n",
    "\n",
    "We save the final selected model to:\n",
    "- `best_model_final.pkl`\n",
    "\n",
    "We do NOT save to DBFS/FileStore.\n",
    "We verify the file exists by listing the directory after saving.\n",
    "\n",
    "If an old version exists, we delete it first (explicitly).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d0874c2-1f2b-4f90-a5d8-04d3a4bf1595",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "\n",
    "final_model_path = os.path.join(BASE_PATH, \"best_model_final.pkl\")\n",
    "\n",
    "# Explicit delete if it already exists\n",
    "if os.path.exists(final_model_path):\n",
    "    print(\"Deleting old model:\", final_model_path)\n",
    "    os.remove(final_model_path)\n",
    "\n",
    "joblib.dump(best_model, final_model_path)\n",
    "\n",
    "print(\"✅ Saved best model to:\", final_model_path)\n",
    "print(\"\\nFiles now in BASE_PATH:\")\n",
    "print(os.listdir(BASE_PATH))\n",
    "\n",
    "assert os.path.exists(final_model_path), \"Save failed: best_model_final.pkl not found.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "58823e75-d3a5-49fb-8733-0a59b695deef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Hyperparameter Tuning — Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f59c4bcd-3590-4b97-8a35-c73c1b369ec8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "\n",
    "param_grid_lr = {\n",
    "    \"C\": [0.1, 1.0, 10.0],\n",
    "    \"solver\": [\"liblinear\"],\n",
    "    \"max_iter\": [200]\n",
    "}\n",
    "\n",
    "grid_lr = GridSearchCV(\n",
    "    log_reg,\n",
    "    param_grid_lr,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=3,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_lr.fit(X_train_float, y_train_arr)\n",
    "\n",
    "print(\"Best LR Params:\", grid_lr.best_params_)\n",
    "print(\"Best LR CV Accuracy:\", grid_lr.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7123ec37-388c-43b7-840b-dbacbcd75560",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Hyperparameter Tuning — Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "acf64bbe-ee75-4062-b9a2-21ccb99b773a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "param_grid_rf = {\n",
    "    \"n_estimators\": [100, 200],\n",
    "    \"max_depth\": [None, 20]\n",
    "}\n",
    "\n",
    "grid_rf = GridSearchCV(\n",
    "    rf,\n",
    "    param_grid_rf,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=3,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_rf.fit(X_train_float, y_train_arr)\n",
    "\n",
    "print(\"Best RF Params:\", grid_rf.best_params_)\n",
    "print(\"Best RF CV Accuracy:\", grid_rf.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b57cfd3b-1235-403a-ac0d-60b2319f91f5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Compare Tuned Models on Test Set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1ae81f3-4b90-4d7d-bc02-13af40091864",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "best_lr = grid_lr.best_estimator_\n",
    "best_rf = grid_rf.best_estimator_\n",
    "\n",
    "lr_test_acc = accuracy_score(y_test_arr, best_lr.predict(X_test_float))\n",
    "rf_test_acc = accuracy_score(y_test_arr, best_rf.predict(X_test_float))\n",
    "\n",
    "print(\"Tuned LR Test Accuracy:\", lr_test_acc)\n",
    "print(\"Tuned RF Test Accuracy:\", rf_test_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de0c13fb-4c67-4661-b288-16942e0b20b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Select Best Model and Save\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c400b406-5eda-4435-8806-f7e6ca9607f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "\n",
    "best_model = best_rf if rf_test_acc > lr_test_acc else best_lr\n",
    "\n",
    "save_path = os.path.join(BASE_PATH, \"best_model_final.pkl\")\n",
    "joblib.dump(best_model, save_path)\n",
    "\n",
    "print(\"Best model saved to:\", save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "60253a48-52fc-4735-a2af-1672ff58284b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Model Performance Summary\n",
    "\n",
    "Two models were tuned using GridSearchCV:\n",
    "\n",
    "• Logistic Regression  \n",
    "• Random Forest Classifier  \n",
    "\n",
    "After hyperparameter tuning and evaluation on the test dataset:\n",
    "\n",
    "- Tuned Logistic Regression Test Accuracy: ~0.951\n",
    "- Tuned Random Forest Test Accuracy: ~0.951\n",
    "\n",
    "Both models achieved nearly identical performance on unseen data.\n",
    "\n",
    "Because the models performed similarly, Logistic Regression was selected as the final model due to its simplicity, interpretability, and lower computational cost.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "45cb5283-ef02-4681-9b33-5a78ddf31e10",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Bias and Fairness Considerations\n",
    "\n",
    "Machine learning models can reflect biases present in the training data.\n",
    "\n",
    "Potential risks include:\n",
    "\n",
    "• Demographic bias  \n",
    "• Underrepresentation of certain groups  \n",
    "• Historical bias embedded in the dataset  \n",
    "\n",
    "To mitigate these risks, it is important to:\n",
    "\n",
    "• Evaluate model performance across different subgroups  \n",
    "• Monitor for disparate impact  \n",
    "• Continuously retrain with updated and diverse data\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "5.3 Trained ML Models: Hyperparameter Tuning",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
